---
title: "Soil Data Analysis"
author: "Joey Hulbert"
date: "4/18/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "/Users/redcedar/ServerFiles/redcedar/") 
```

```{r include=FALSE}
library(tidyverse)
library(randomForest)
library(caret)
library(rpart)
library(knitr)
```


# Purpose

The purpose of this markdown document is to list the steps we followed for refining the models using soils data only.

# Data

The data used in the below models are described in the [Data Wrangle folder](./data-wrangle). 

## Response variables

**Note the below analysis uses the iNat data with 1510 observations. Amazing!**

* Response variables to consider
  + Number of unhealthy trees
  + Tree canopy symptoms

Below we compare models using canopy symptoms as the response variable

## Explanatory variables

* Explanatory variables included
  + iNat data
    + explanatory variables such as tree size
  + Soils data
    + Muggatt 
    + Component
      + Component Ecological Class (coecoclass) - related to component
    + Valu1
    
```{r}
data <- read.csv("./data/observations-223649.csv")
#data.filtered <- data %>% select(c("id","field.tree.canopy.symptoms")) - remove all data except response variable of interest
```

```{r}
wasoils <- read.csv("./data/soils_extract_files/WA_soils_extract_1500_valu1.csv",header=TRUE)
orsoils <- read.csv("./data/soils_extract_files/OR_soils_extract_1500_valu1.csv",header=TRUE)
wasoils <- rename(wasoils, id = ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
orsoils <- rename(orsoils, id = ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
# orsoils$compone_71 <- as.integer(orsoils$compone_71) # not sure why, but the compone_71 factor was recognized as a characer rather than an integer in the oregon extract
pnwsoils <- bind_rows(wasoils,orsoils)
```

```{r}
#combo.normals <- left_join(data,normals,by="id")  %>% left_join(.,topo,by="id") %>% left_join(.,pnwsoils,by="id")
#combo.decade <- left_join(data,lastdecade,by="id")  %>% left_join(.,topo,by="id") %>% left_join(.,pnwsoils,by="id") 
combo <- left_join(data,pnwsoils,by="id")
```

```{r}
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="Multiple Symptoms"] <-"Multiple Symptoms (please list in Notes)"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="multiple symptoms"] <-"Multiple Symptoms (please list in Notes)"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="thinning foliage"] <-"Thinning Canopy"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="healthy"] <-"Healthy"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="dead top"] <-"Old Dead Top (needles already gone)"
combo <- combo %>% droplevels()
combo$field.tree.canopy.symptoms <- as.factor(combo$field.tree.canopy.symptoms)
#levels(combo$field.tree.canopy.symptoms)
```

# Data wrangling

There are multiple methods to group the response variables deepening on desired resolution or fineness of the model. 

* Response grouping options
  + Original (no change)
  + Filtered Symptoms
    + We could drop trees outside of main symptom classes
       + Note loss of data outside of categories
  + Reclassified symptoms
    + Here we can created an 'other' variable to represent trees with the below symptoms
        + extra cone crop
        + yellowing canopy
    + We can also group trees with 'old dead tops' and 'new dead tops' into a 'dead top' category
  + Binary (healthy/unhealthy)

For now, we can move forward with the binary response grouping because it is the broadest and presumably the easiest for the model to classify with. 


All tree health categories

```{r}
combo %>% group_by(field.tree.canopy.symptoms) %>% count()
```

## Filter Data


### Filter observations

Before filtering, there were `nrow(combo)` observations in the iNat data. However, these include observations from Canada, Washington, Oregon, Idaho, Montana, California.

Filter trees to only those with soils data (Oregon and Washington)

```{r}
combo.filtered <- combo %>% filter(RASTERVALU>=0, na.rm=TRUE)
```

After filtering, there are `nrow(combo.filtered)` observations from Oregon and Washington.

### Filter columns or predictors

We also need to filter the data to only include response and explanatory variables we're interested in. For example, whether a sound clip was included in the iNat data is not important. 

We also need to remove other response variables like "field.percent.canopy.affected...." so it is not used as a predictor for tree health. 

> Note it might be interesting to know if the user was an important factor in predicting if the tree is healthy/unhealthy. 

There are also a number of factors that should probably be removed because they may be biasing the data. For example, only trees with the 'other factor' question may only be answered for unhealthy trees. We need to think about this a bit more. 

First remove iNat factors not useful as explanatory variables (e.g. observed_on)

```{r}
combo.filtered <- combo.filtered %>% select(-c("field.optional...site.type",
                                      "field.optional...site.hydrology",
                                      "field.optional...site.location.description",
                                      "field.optional...site.area.disturbance.level",
                                      "field.optional...tree.size",
  "field.optional...slope.position",
  "field.optional...did.the.tree.have.heat.damage",
,"field.percent.canopy.affected...."
,"field.number.of.additional.unhealthy.trees..of.same.species..in.area..within.sight."
,"field.percent.of.trees..of.same.species..within.sight.that.are.unhealthy"
,"field.optional...access.to.water"
,"id"  
,"observed_on_string"                                                                     
,"observed_on"                                                                            
,"time_observed_at"                                                                       
,"time_zone"                                                                              
,"user_id"                                                                                
,"user_login"                                                                             
,"created_at"                                                                             
,"updated_at"
,"quality_grade"                                                                          
,"license"                                                                                
,"url"                                                                                    
,"image_url"                                                                              
,"sound_url"                                                                              
,"tag_list"                                                                               
,"description"                                                                            
,"num_identification_agreements"                                                          
,"num_identification_disagreements"                                                       
,"captive_cultivated"                                                                     
,"oauth_application_id"                                                                   
,"place_guess"                                                                            
,"latitude"                                                                               
,"longitude"                                                                              
,"positional_accuracy"                                                                    
,"private_place_guess"                                                                    
,"private_latitude"                                                                       
,"private_longitude"                                                                      
,"public_positional_accuracy"                                                             
,"geoprivacy"                                                                             
,"taxon_geoprivacy"                                                                       
,"coordinates_obscured"                                                                   
,"positioning_method"                                                                     
,"positioning_device"                                                                     
,"place_town_name"                                                                        
,"place_county_name"                                                                      
,"place_state_name"                                                                       
,"place_country_name"                                                                     
,"place_admin1_name"                                                                      
,"place_admin2_name"                                                                      
,"species_guess"                                                                          
,"scientific_name"
,"common_name"                                                                            
,"iconic_taxon_name"                                                                      
,"taxon_id"          
,"field.other.factors...are.there.signs.or.symptoms.of.insect..diseases..or.other.damage."
,"field.optional...what..other.factors..were.observed." 
, "field.optional...were.there.any.other.unhealthy.plant.species.on.the.site."             
 ,"field.optional...timing.of.symptoms.estimate"                                           
, "field.optional...estimated.time.spent.to.make.this.observation....of.minutes."          
, "field.optional...can.we.follow.up.with.you."
,"field.notes"                 
))
# combo.filtered <- combo.filtered[c(45,50:59,68:332,337:341,355:394,396:503,510:774)] 
```

Then, remove specific soils variables not useful as explanatory variables (e.g. MUKEY)

#### Removed from muaggatt

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"OID_"                       
,"Field1"                      
,"lat"                         
,"long"
,"el"
,"RASTERVALU" 
,"OR_MapunitRaster_10m"
,"VAT_MapunitRaster_10m_Count"
,"VAT_MapunitRaster_10m_MUKEY"
,"muaggatt_OBJECTID"
,"muaggatt_mukey"
))
```

#### Removed from component

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"component_OBJECTID" 
,"component_mukey"           
,"component_cokey"
))
```

#### Removed from coecoclass

We kept  "coecoclass_ecoclassname" and "coecoclass_ecoclasstypename"

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"coecoclass_OBJECTID" 
,"coecoclass_ecoclassref"
,"coecoclass_ecoclassid"
,"coecoclass_cokey"           
,"coecoclass_coecoclasskey"
))
```

#### Removed from valu1

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"Valu1_OBJECTID" 
,"Valu1_mukey"
))
```

### Filter near zero standard deviations

Remove variables that have near zero standard deviations (entire column is same value)

```{r include=FALSE}
#nearZeroVar(combo.filtered)
combo.filtered.nearzerovar <- combo.filtered[,-nearZeroVar(combo.filtered)]
#write.csv(combo.decade.filtered,file="./data/troubleshoot.csv")
```

```{r}
combo.filtered.nearzerovar <-as.data.frame(unclass(combo.filtered.nearzerovar),stringsAsFactors=TRUE) #change all chars to factors
```

## (Not included) Remove variables with missing data

We could also remove columns without any data (entire column is NAs)

```{r}
#Note the below code applies to combo.filtered rather than combo.filtered.nearzerovar

combo.filtered <- combo.filtered[,colSums(is.na(combo.filtered)) < nrow(combo.filtered) * 0.8] # Keeps columns that have data for at least 80% of the observations
#combo.filtered <- combo.filtered[colSums(!is.na(combo.filtered)) > 0] - removes columns that are completely NAs
# df[, colSums(is.na(df)) < nrow(df) * 0.5] is command for only keeping data with at least half
```

> **Note we chose to only keep  variables (columns) that contained data for at least 80% of the data**

Then check number of NAs per remaining column

```{r echo=TRUE, include=FALSE}
colSums(is.na(combo.filtered))
```

* The below variables are examples of those without much data (column contains mostly NAs)
  + component_rsprod_h
  + component_rsprod_l
  + component_rsprod_r
  + component_totalsub_h
  + component_totalsub_l
  + component_totalsub_r
  + component_reannualprecip_r
  + component_reannualprecip_l
  + component_reannualprecip_h


## Group response variables to binary values

```{r}
level_key <- c("Healthy" = "Healthy", "Thinning Canopy" = "Unhealthy", "New Dead Top (red or brown needles still attached)" = "Unhealthy", "Old Dead Top (needles already gone)" = "Unhealthy", "Tree is dead" = "Unhealthy", "Multiple Symptoms (please list in Notes)" = "Unhealthy", "Extra Cone Crop" = "Unhealthy", "Browning Canopy" = "Unhealthy","Branch Dieback or 'Flagging'" = "Unhealthy", "Other (please describe in Notes)" = "Unhealthy", "Yellowing Canopy" = "Unhealthy")

binary <- combo.filtered.nearzerovar
binary$field.tree.canopy.symptoms <- recode_factor(binary$field.tree.canopy.symptoms, !!!level_key)
#levels(binary$field.tree.canopy.symptoms)
binary <- binary %>% filter(field.tree.canopy.symptoms!="Candelabra top or very old spike top (old growth)") %>% droplevels()
binary$field.tree.canopy.symptoms <- as.factor(binary$field.tree.canopy.symptoms)
```

Binary tree health categories

```{r}
binary %>% group_by(field.tree.canopy.symptoms) %>% count()
```





# Approach

* General approach
  + build full model using binary response grouping variable
    + binary response 
  + refine model to remove redundant explanatory variables
  

# Models

* Random forest model criteria
  + nearzero variation columns were removed
  + Data were imputed prior to model building. 
  + number of splits was not defined to allow automatic selection,
  + ntree = 2001, importance = TRUE, proximity = TRUE, na.action = na.omit
  + seed was set for reproducability with: set.seed(71)





## Impute data

#### Impute data

##### Overall Imputed data

We continue to get the below error, but were able to work around it by imputing the data. 

> Error in randomForest.default(m, y, ...) : Need at least two classes to do classification.

To impute the data we have to remove factors with >53 levels. For example, 'component_taxclnam' has 132 levels


```{r echo=TRUE, include=FALSE}
#The below code lists the number of levels for the variables that are factors. 
#Note you need to remove echo=TRUE,include=FALSE to run this by clicking arrow.
for (n in names(binary))
  if (is.factor(binary[[n]])) {
    print(n)
    print(length(levels(binary[[n]])))
  }
```

* The following factors had more than 53 levels
  + "muaggatt_musym" 
  + "muaggatt_muname"
  + "component_compname"
  + "component_geomdesc"
  + "component_taxclname"
  + "component_taxsubgrp"
  + "component_taxgrtgroup"
  + "coecoclass_ecoclassname"

```{r}
less.fifty.three <- binary %>% select(-c("muaggatt_musym","muaggatt_muname","component_compname","component_geomdesc","component_taxclname","component_taxsubgrp","component_taxgrtgroup","coecoclass_ecoclassname")) 
```

Imputed data table

```{r}
data.imputed <- rfImpute(field.tree.canopy.symptoms ~ ., data= less.fifty.three, iter=6)
```


#### Full Model

```{r full rf model}
set.seed(71)
rf <- randomForest(field.tree.canopy.symptoms ~ ., data=data.imputed, ntree=2001, importance=TRUE, na.action=na.omit, proximity=TRUE)
```

```{r}
rf
```

```{r}
plot(rf)
```

```{r fig.height=6,fig.width=9}
#Below code copied from: https://github.com/StatQuest/random_forest_demo/blob/master/random_forest_demo.R as described here: https://www.youtube.com/watch?v=6EXPYzbfLCE

## Start by converting the proximity matrix into a distance matrix. 

distance.matrix <- as.dist(1-rf$proximity)

mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)

## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)

## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
  X=mds.values[,1],
  Y=mds.values[,2],
  Status=data.imputed$field.tree.canopy.symptoms)

ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) + 
  geom_text(aes(color=Status)) +  
  stat_ellipse(geom="polygon",aes(fill=Status,color=Status),alpha=0.45) +
  theme_bw() + 
  scale_color_manual(values=c("#7fcdbb","#fe9929")) +
  scale_fill_manual(values=c("#7fcdbb","#fe9929")) +
  xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
  ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
  ggtitle("MDS plot using (1 - Random Forest Proximities)")

#By default, the stat_ellipse function draws a 95% confidence level for a multivariate t-distribution. You can modify this level with level argument.

#more info for ellipse https://r-charts.com/correlation/scatter-plot-ellipses-ggplot2/
```

```{r fig.height=9,fig.width=12}
varImpPlot(rf)
```

#### Limited number of splits 

```{r full rf model}
set.seed(71)
rf <- randomForest(field.tree.canopy.symptoms ~ ., data=data.imputed, ntree=2001, importance=TRUE, na.action=na.omit, proximity=TRUE)
```

```{r}
rf
```

```{r}
plot(rf)
```

```{r fig.height=6,fig.width=9}
#Below code copied from: https://github.com/StatQuest/random_forest_demo/blob/master/random_forest_demo.R as described here: https://www.youtube.com/watch?v=6EXPYzbfLCE

## Start by converting the proximity matrix into a distance matrix. 

distance.matrix <- as.dist(1-rf$proximity)

mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)

## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)

## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
  X=mds.values[,1],
  Y=mds.values[,2],
  Status=data.imputed$field.tree.canopy.symptoms)

ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) + 
  geom_text(aes(color=Status)) +  
  stat_ellipse(geom="polygon",aes(fill=Status,color=Status),alpha=0.45) +
  theme_bw() + 
  scale_color_manual(values=c("#7fcdbb","#fe9929")) +
  scale_fill_manual(values=c("#7fcdbb","#fe9929")) +
  xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
  ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
  ggtitle("MDS plot using (1 - Random Forest Proximities)")

#By default, the stat_ellipse function draws a 95% confidence level for a multivariate t-distribution. You can modify this level with level argument.

#more info for ellipse https://r-charts.com/correlation/scatter-plot-ellipses-ggplot2/
```

```{r fig.height=9,fig.width=12}
varImpPlot(rf)
```