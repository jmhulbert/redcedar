---
title: "Full Environmental Predictor Analyses"
author: "Joey Hulbert"
date: "5/29/2022"
output: html_document
---

|            |            |            |            |
|:----------:|:----------:|:----------:|:----------:|
|[Home](https://jmhulbert.github.io/redcedar)|[Data Wrangling](./data-wrangle/Data-Wrangle-v1.html)|[Data Analyses](./analyses/)|[Data Visualization](./data-visualization/)|
|             |           |            |            |

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "/Users/redcedar/ServerFiles/redcedar/") 
```

```{r include=FALSE}
library(tidyverse)
library(randomForest)
library(caret)
library(rpart)
library(knitr)
```

# Purpose

# Approach

# Data

## iNat
```{r}
data <- read.csv("./data/observations-223649.csv")
#data.filtered <- data %>% select(c("id","field.tree.canopy.symptoms")) - remove all data except response variable of interest
```

## Soils

```{r}
wasoils <- read.csv("./data/soils_extract_files/WA_soils_extract_1500_valu1.csv",header=TRUE)
orsoils <- read.csv("./data/soils_extract_files/OR_soils_extract_1500_valu1.csv",header=TRUE)
wasoils <- rename(wasoils, id = ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
orsoils <- rename(orsoils, id = ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
# orsoils$compone_71 <- as.integer(orsoils$compone_71) # not sure why, but the compone_71 factor was recognized as a characer rather than an integer in the oregon extract
pnwsoils <- bind_rows(wasoils,orsoils)
```

## Climate

```{r}
normals <- read.csv("./data/gps1500_Normal_1991_2020MSY.csv",na.string ="-9999")
colnames(normals) <- str_c("norm_",colnames(normals)) #change column names - not to be confused with decadal data
normals <- rename(normals, id = norm_ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
```

```{r}
lastdecade <- read.csv("./data/gps1500_Decade_2011_2020MSY.csv",na.string ="-9999")
lastdecade <- rename(lastdecade, id = ID2) #rename column 'ID2' (changed for ClimateNA tool) back to 'id'
```

## Topo

```{r}
CTI <- read.csv("./data/topo_extract_files/CTI_extract_1500.csv")
CTI <- rename(CTI, CTI_VALUE = RASTERVALU)
CTI <- rename(CTI, id = ID2)
CTI <- CTI[c(3,7)]

HLI <- read.csv("./data/topo_extract_files/HLI_extract_1500.csv")
HLI <- rename(HLI, HLI_VALUE = RASTERVALU)
HLI <- rename(HLI, id = ID2)
HLI <- HLI[c(3,7)]

IMI <- read.csv("./data/topo_extract_files/IMI_extract_1500.csv")
IMI <- rename(IMI, IMI_VALUE = RASTERVALU)
IMI <- rename(IMI, id = ID2)
IMI <- IMI[c(3,7)]

SDS <- read.csv("./data/topo_extract_files/SDS_extract_1500.csv")
SDS <- rename(SDS, SDS_VALUE = RASTERVALU)
SDS <- rename(SDS, id = ID2)
SDS <- SDS[c(3,7)]

SP <- read.csv("./data/topo_extract_files/SP_extract_1500.csv")
SP <- rename(SP, SP_VALUE = RASTERVALU)
SP <- rename(SP, id = ID2)
SP <- SP[c(3,7)]

DEM <- read.csv("./data/topo_extract_files/DEM_extract_1500.csv")
DEM <- rename(DEM, DEM_VALUE = RASTERVALU)
DEM <- rename(DEM, id = ID2)
DEM <- DEM[c(3,7)]

TRASP <- read.csv("./data/topo_extract_files/TRASP_extract_1500.csv")
TRASP <- rename(TRASP, TRASP_VALUE = RASTERVALU)
TRASP <- rename(TRASP, id = ID2)
TRASP <- TRASP[c(3,7)]
```  

## Combined

```{r}
#combo.normals <- left_join(data,normals,by="id")  %>% left_join(.,topo,by="id") %>% left_join(.,pnwsoils,by="id")
#combo.decade <- left_join(data,lastdecade,by="id")  %>% left_join(.,topo,by="id") %>% left_join(.,pnwsoils,by="id") 
combo <- left_join(data,pnwsoils,by="id") %>% left_join(.,normals,by="id") %>% left_join(.,lastdecade,by="id") %>% left_join(.,CTI,by="id") %>% left_join(.,HLI,by="id") %>% left_join(.,IMI,by="id") %>% left_join(.,SDS,by="id") %>% left_join(.,SP,by="id") %>% left_join(.,DEM,by="id") %>% left_join(.,TRASP,by="id")  
```

# Data Wrangle

```{r}
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="Multiple Symptoms"] <-"Multiple Symptoms (please list in Notes)"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="multiple symptoms"] <-"Multiple Symptoms (please list in Notes)"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="thinning foliage"] <-"Thinning Canopy"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="healthy"] <-"Healthy"
combo$field.tree.canopy.symptoms[combo$field.tree.canopy.symptoms=="dead top"] <-"Old Dead Top (needles already gone)"
combo <- combo %>% droplevels()
combo$field.tree.canopy.symptoms <- as.factor(combo$field.tree.canopy.symptoms)
#levels(combo$field.tree.canopy.symptoms)
```

```{r}
combo %>% group_by(field.tree.canopy.symptoms) %>% count()
```

## Filter data

### Filter observatoins

We also want to filter observations to only those within Oregon and Washington as those are the only observations we extracted TOPO data for.

```{r}
combo.filtered <- combo %>% filter(HLI_VALUE!="NA",na.rm=TRUE)
```

```{r echo=TRUE, include=FALSE}
#colSums(is.na(combo.filtered))
```

## Remove unwanted predictors

### iNat variables

* Note the following fields were removed because they're not explanatory variables for the below model
  + "field.optional...were.there.any.other.unhealthy.plant.species.on.the.site."             
  + "field.optional...timing.of.symptoms.estimate"                                           
  + "field.optional...estimated.time.spent.to.make.this.observation....of.minutes."          
  + "field.optional...can.we.follow.up.with.you."
  + "field.percent.canopy.affected...."
  + "field.number.of.additional.unhealthy.trees..of.same.species..in.area..within.sight."
  + "field.percent.of.trees..of.same.species..within.sight.that.are.unhealthy"
  + "field.notes"

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"id"
,"observed_on_string"                                                                     
,"observed_on"                                                                            
,"time_observed_at"                                                                       
,"time_zone"                                                                              
,"user_id"                                                                                
,"user_login"                                                                             
,"created_at"                                                                             
,"updated_at"
,"quality_grade"                                                                          
,"license"                                                                                
,"url"                                                                                    
,"image_url"                                                                              
,"sound_url"                                                                              
,"tag_list"                                                                               
,"description"                                                                            
,"num_identification_agreements"                                                          
,"num_identification_disagreements"                                                       
,"captive_cultivated"                                                                     
,"oauth_application_id"                                                                   
,"place_guess"                                                                            
,"latitude"                                                                               
,"longitude"                                                                              
,"positional_accuracy"                                                                    
,"private_place_guess"                                                                    
,"private_latitude"                                                                       
,"private_longitude"                                                                      
,"public_positional_accuracy"                                                             
,"geoprivacy"                                                                             
,"taxon_geoprivacy"                                                                       
,"coordinates_obscured"                                                                   
,"positioning_method"                                                                     
,"positioning_device"                                                                     
,"place_town_name"                                                                        
,"place_county_name"                                                                      
,"place_state_name"                                                                       
,"place_country_name"                                                                     
,"place_admin1_name"                                                                      
,"place_admin2_name"                                                                      
,"species_guess"                                                                          
,"scientific_name"
,"common_name"                                                                            
,"iconic_taxon_name"                                                                      
,"taxon_id"
, "field.optional...were.there.any.other.unhealthy.plant.species.on.the.site."             
 ,"field.optional...timing.of.symptoms.estimate"                                           
, "field.optional...estimated.time.spent.to.make.this.observation....of.minutes."          
, "field.optional...can.we.follow.up.with.you."
,"field.notes"
,"field.percent.canopy.affected...."
,"field.number.of.additional.unhealthy.trees..of.same.species..in.area..within.sight."
,"field.percent.of.trees..of.same.species..within.sight.that.are.unhealthy"
,"field.optional...did.the.tree.have.heat.damage"
))
# combo.filtered <- combo.filtered[c(45,50:59,68:332,337:341,355:394,396:503,510:774)] 
```

### Soil variables

Then, remove specific soils variables not useful as explanatory variables (e.g. MUKEY)

#### Removed from muaggatt

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"OID_"                       
,"Field1"                      
,"lat"                         
,"long"
,"el"
,"RASTERVALU" 
,"OR_MapunitRaster_10m"
,"VAT_MapunitRaster_10m_Count"
,"VAT_MapunitRaster_10m_MUKEY"
,"muaggatt_OBJECTID"
,"muaggatt_mukey"
))
```

#### Removed from component

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"component_OBJECTID" 
,"component_mukey"           
,"component_cokey"
))
```

#### Removed from coecoclass

We kept  "coecoclass_ecoclassname" and "coecoclass_ecoclasstypename"

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"coecoclass_OBJECTID" 
,"coecoclass_ecoclassref"
,"coecoclass_ecoclassid"
,"coecoclass_cokey"           
,"coecoclass_coecoclasskey"
))
```

#### Removed from valu1

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"Valu1_OBJECTID" 
,"Valu1_mukey"
))
```


### Climate variables

Then, remove specific climate variables not useful as explanatory variables (e.g. norm_Latitutde)

```{r}
combo.filtered <- combo.filtered %>% select(-c(
"X" 
,"Latitude"                                    
,"Longitude"
,"norm_X"                                                                                   
,"norm_Latitude"                                                                            
,"norm_Longitude"                                                                           
,"norm_Elevation"))
```

## Filter near zero standard deviations

Remove variables with variables that have near zero standard deviations (entire column is same value)

```{r include=FALSE}
#nearZeroVar(combo.filtered)
combo.filtered.nearzerovar <- combo.filtered[,-nearZeroVar(combo.filtered)]
#write.csv(combo.decade.filtered,file="./data/troubleshoot.csv")
```

```{r}
combo.filtered.nearzerovar <-as.data.frame(unclass(combo.filtered.nearzerovar),stringsAsFactors=TRUE) #change all chars to factors
```

## (Optional?) Remove variables with missing data

We can also remove columns without any data (entire column is NAs)

```{r}
combo.filtered <- combo.filtered[,colSums(is.na(combo.filtered)) < nrow(combo.filtered) * 0.8] # Keeps columns that have data for at least 80% of the observations
#combo.filtered <- combo.filtered[colSums(!is.na(combo.filtered)) > 0] - removes columns that are completely NAs
# df[, colSums(is.na(df)) < nrow(df) * 0.5] is command for only keeping data with at least half
```

> **Note we chose to only keep variables (columns) that contained data for at least 80% of the data**

Then check number of NAs per remaining column

```{r echo=TRUE, include=FALSE}
colSums(is.na(combo.filtered))
```

* The below variables are examples of those without much data (column contains mostly NAs)
  + component_rsprod_h
  + component_rsprod_l
  + component_rsprod_r
  + component_totalsub_h
  + component_totalsub_l
  + component_totalsub_r
  + component_reannualprecip_r
  + component_reannualprecip_l
  + component_reannualprecip_h



## Group response variables to binary values

```{r}
level_key <- c("Healthy" = "Healthy", "Thinning Canopy" = "Unhealthy", "New Dead Top (red or brown needles still attached)" = "Unhealthy", "Old Dead Top (needles already gone)" = "Unhealthy", "Tree is dead" = "Unhealthy", "Multiple Symptoms (please list in Notes)" = "Unhealthy", "Extra Cone Crop" = "Unhealthy", "Browning Canopy" = "Unhealthy","Branch Dieback or 'Flagging'" = "Unhealthy", "Other (please describe in Notes)" = "Unhealthy", "Yellowing Canopy" = "Unhealthy")

binary <- combo.filtered.nearzerovar
binary$field.tree.canopy.symptoms <- recode_factor(binary$field.tree.canopy.symptoms, !!!level_key)
#levels(binary$field.tree.canopy.symptoms)
binary <- binary %>% filter(field.tree.canopy.symptoms!="Candelabra top or very old spike top (old growth)") %>% droplevels()
binary$field.tree.canopy.symptoms <- as.factor(binary$field.tree.canopy.symptoms)
```

Binary tree health categories

```{r}
binary %>% group_by(field.tree.canopy.symptoms) %>% count()
```

## Normal, Monthless Model

```{r}
normal.monthless.binary <- binary[-c(169:313,391:613)]
```

## Impute data

We continue to get the below error, but were able to work around it by imputing the data. 

> Error in randomForest.default(m, y, ...) : Need at least two classes to do classification.

To impute the data we have to remove factors with >53 levels. For example, 'component_taxclnam' has 132 levels


```{r echo=TRUE, include=FALSE}
#The below code lists the number of levels for the variables that are factors. 
#Note you need to remove echo=TRUE,include=FALSE to run this by clicking arrow.
for (n in names(binary))
  if (is.factor(binary[[n]])) {
    print(n)
    print(length(levels(binary[[n]])))
  }
```

* The following factors had more than 53 levels
  + "muaggatt_musym" 
  + "muaggatt_muname"
  + "component_compname"
  + "component_geomdesc"
  + "component_taxclname"
  + "component_taxsubgrp"
  + "component_taxgrtgroup"
  + "coecoclass_ecoclassname"

```{r}
less.fifty.three <- normal.monthless.binary %>% select(-c("muaggatt_musym","muaggatt_muname","component_compname","component_geomdesc","component_taxclname","component_taxsubgrp","component_taxgrtgroup","coecoclass_ecoclassname")) 
```

Imputed data table

```{r}
data.imputed <- rfImpute(field.tree.canopy.symptoms ~ ., data= less.fifty.three, iter=6)
```


# Approach

* General approach
  + build full model using binary response grouping variable and climate response variable (see climate data analysis)
    + binary response 
  + refine model to remove redundant explanatory variables
    + use refined (normal, monthless model to test whole dataset)
  
# Models

* Random forest model criteria
  + nearzero variation columns were removed
  + (optional, not applied but should be considered) columns with missing data [more than 80%?] should be removed?
  + Data were imputed prior to model building (full and soils analyses only). 
  + number of splits was not defined to allow automatic selection,
  + ntree = 2001, importance = TRUE, proximity = TRUE, na.action = na.omit
  + seed was set for reproducability with: set.seed(71)

```{r full rf model}
set.seed(71)
rf <- randomForest(field.tree.canopy.symptoms ~ ., data=data.imputed, ntree=2001, importance=TRUE, na.action=na.omit, proximity=TRUE)
```

```{r}
rf
```

```{r}
plot(rf)
```

```{r fig.height=6,fig.width=9}
#Below code copied from: https://github.com/StatQuest/random_forest_demo/blob/master/random_forest_demo.R as described here: https://www.youtube.com/watch?v=6EXPYzbfLCE

## Start by converting the proximity matrix into a distance matrix. 

distance.matrix <- as.dist(1-rf$proximity)

mds.stuff <- cmdscale(distance.matrix, eig=TRUE, x.ret=TRUE)

## calculate the percentage of variation that each MDS axis accounts for...
mds.var.per <- round(mds.stuff$eig/sum(mds.stuff$eig)*100, 1)

## now make a fancy looking plot that shows the MDS axes and the variation:
mds.values <- mds.stuff$points
mds.data <- data.frame(Sample=rownames(mds.values),
  X=mds.values[,1],
  Y=mds.values[,2],
  Status=data.imputed$field.tree.canopy.symptoms)

ggplot(data=mds.data, aes(x=X, y=Y, label=Sample)) + 
  geom_text(aes(color=Status)) +  
  stat_ellipse(geom="polygon",aes(fill=Status,color=Status),alpha=0.45) +
  theme_bw() + 
  scale_color_manual(values=c("#7fcdbb","#fe9929")) +
  scale_fill_manual(values=c("#7fcdbb","#fe9929")) +
  xlab(paste("MDS1 - ", mds.var.per[1], "%", sep="")) +
  ylab(paste("MDS2 - ", mds.var.per[2], "%", sep="")) +
  ggtitle("MDS plot using (1 - Random Forest Proximities)")

#By default, the stat_ellipse function draws a 95% confidence level for a multivariate t-distribution. You can modify this level with level argument.

#more info for ellipse https://r-charts.com/correlation/scatter-plot-ellipses-ggplot2/
```

```{r fig.height=9,fig.width=12}
varImpPlot(rf)
```
